---
format:
  pdf:
    documentclass: article
    fontsize: 12pt
    monofont: "Consolas"
    extra-dependencies:
      - float
  html: 
    theme: cosmo
title: Laboratório 03 - Planejamento e Análise de Experimentos (MAE0316)
date: last-modified
date-format: long
lang: pt-BR
geometry:
    - left=2cm
    - top=2cm
    - bottom=2cm
    - right=2cm
author: 
    - name: Caio M. de Almeida - 15444560
    - name: Eduardo Yukio G. Ishihara - 15449012
    - name: Gustavo S. Garone - 15458155
    - name: Ian B. Loures - 15459667
    - name: João Victor G. de Sousa - 15463912
execute:
  echo: false
  keep-ipynb: true
  warning: false
  message: false
fig-align: center
fig-cap-location: top
fig-pos: H
tbl-pos: H
engine: knitr
---

`\vspace{-0.5cm}\noindent\rule{\textwidth}{1pt}`{=latex}

```{css}
#| echo: false
p {
  text-align: justify
}
```

```{r}
#| output: false
# Carrega pacotes
library(tidyr)
library(knitr)
library(dplyr)
library(ggplot2)
library(patchwork)
library(readxl)
library(vegan)
library(npmv)
library(lmPerm)
library(devtools)
library(car)
library(readxl)
# library(pairwiseAdonis)
set.seed(123)
```

Neste laboratório, usaremos "$.$" como separador decimal, quatro dígitos decimais e a _seed_ 123.

# Exercício 1

```{r}
#| output: false
# Carrega dados para o exercício 1
dados <- tibble(read_excel("./Besouro.xlsx"))
# Corrigir NA na posição Trat 25 -> T1
dados$Trat[25] <- "T1"
# Transforma Planta e Tratamento em fator
dados$Planta <- as.factor(dados$Planta)
dados$Trat <- as.factor(dados$Trat)
```

## Item a

A unidade experimental são as folhas, enquanto a unidade
observacional são seus quadrantes.

## Item b

Um DCA (Delineamento Completamente Aleatorizado) realiza a alocação
aleatoriamente dos tratamentos às unidades experimentais, enquanto um DABC
(Delineamento Aleatorizado em Blocos Completos) designa para cada bloco pelo
menos uma repetição de cada tratamento.

```{r}
modeloDCA <- lm(Obser ~ Trat, data = dados)
modeloDABC <- lm(Obser ~ Planta + Trat, data = dados)
```

```{r}
#| label: tbl-DCA-anova
#| tbl-cap: "ANOVA para o modelo DCA"
anovaDCA <- anova(modeloDCA)
kable(anovaDCA, digits = 4)
```

```{r}
#| label: tbl-DABC-anova
#| tbl-cap: "ANOVA para o modelo DABC"
anovaDABC <- anova(modeloDABC)
kable(anovaDABC, digits = 4)
```

Vemos efeito significativo dos tratamentos em ambos modelos, como indica a
@tbl-DABC-anova e a @tbl-DCA-anova. Porém, o modelo DABC efeito significativo
para o fator Planta, o que indica que o modelo DABC é mais adequado para esses
dados.

### Verificação das assunções

Primeiramente, verificaremos as assunções do modelo com blocos (DABC)

```{r}
#| label: fig-DABC-diagnostics
#| fig-cap: "Gráfico Resíduos x Ajustados para modelo DABC"
residuos <- resid(modeloDABC)
p1 <- ggplot(data = dados, aes(x = fitted(modeloDABC), y = residuos)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Valores ajustados", y = "Resíduos") +
  theme_minimal()
p1
```

O gráfico de resíduos vs ajustados na @fig-DABC-diagnostics não apresenta
padrões evidentes, sugerindo homocedasticidade dos resíduos. Prosseguiremos com
o teste de Shapiro-Wilk para normalidade dos resíduos, com resultados na
@tbl-DABC-shapiro, e um QQ-plot para visualização, na @fig-QQ-DABC.

```{r}
#| label: tbl-DABC-shapiro
#| tbl-cap: "Teste de Shapiro-Wilk para os resíduos do modelo DABC"
shapiroDABC <- shapiro.test(residuos)

tibleshapiroDABC <- tibble(
  Estatística = shapiroDABC$statistic,
  "Valor-p" = shapiroDABC$p.value
)

kable(tibleshapiroDABC, digits = 4)
```

```{r}
#| label: fig-QQ-DABC
#| fig-cap: "QQ-Plot dos resíduos do modelo DABC"
ggplot(data = dados, aes(sample = residuos)) +
  stat_qq() +
  stat_qq_line(color = "red") +
  labs(x = "Quantis teóricos", y = "Quantis amostrais") +
  theme_minimal()
```

Finalmente, com normalidade não rejeitada, aplicamos o teste de Bartlett para
verificar homocedasticidade, com resultados na @tbl-DABC-bartlett.

```{r}
#| label: tbl-DABC-bartlett
#| tbl-cap: "Teste de Bartlett para os resíduos do modelo DABC"
bartlettDABC <- bartlett.test(residuos ~ Trat, data = dados)
tiblebartlettDABC <- tibble(
  Estatística = bartlettDABC$statistic,
  "Valor-p" = bartlettDABC$p.value
)
kable(tiblebartlettDABC, digits = 4)
```

Deste diagnóstico, concluímos que o modelo DABC satisfaz as assunções de
normalidade e homocedasticidade dos resíduos. Dessa forma, por incluir `Planta`
no modelo, o DABC é um modelo mais completo para esses dados. Sendo assim,
poderíamos parar nossa análise por aqui, mas seguiremos com diagnóstico do
modelo DCA.

Agora, verificaremos as assunções do modelo sem blocos (DCA)

```{r}
#| label: fig-DCA-diagnostics
#| fig-cap: "Gráfico Resíduos x Ajustados para modelo DCA"
residuosDCA <- resid(modeloDCA)
p2 <- ggplot(data = dados, aes(x = fitted(modeloDCA), y = residuosDCA)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Valores ajustados", y = "Resíduos") +
  theme_minimal()
p2
```

O gráfico de resíduos vs ajustados na @fig-DCA-diagnostics pode indicar
heterocedasticidade dos resíduos. Prosseguiremos com o teste de Shapiro-Wilk
para normalidade dos resíduos, com resultados na @tbl-DCA-shapiro, e um QQ-plot
para visualização, na @fig-QQ-DCA.

```{r}
#| label: tbl-DCA-shapiro
#| tbl-cap: "Teste de Shapiro-Wilk para os resíduos do modelo DCA"
shapiroDCA <- shapiro.test(residuosDCA)
tibleshapiroDCA <- tibble(
  Estatística = shapiroDCA$statistic,
  "Valor-p" = shapiroDCA$p.value
)
kable(tibleshapiroDCA, digits = 4)
```

```{r}
#| label: fig-QQ-DCA
#| fig-cap: "QQ-Plot dos resíduos do modelo DCA"
ggplot(data = dados, aes(sample = residuosDCA)) +
  stat_qq() +
  stat_qq_line(color = "red") +
  labs(x = "Quantis teóricos", y = "Quantis amostrais") +
  theme_minimal()
```

O QQ-plot na @fig-QQ-DCA sugere que os resíduos podem não seguir uma
distribuição normal, além disso, o teste de Shapiro-Wilk na @tbl-DCA-shapiro
apresentou um `valor-p` bem mais baixo que do modelo DABC, indicando uma maior
evidência contra a normalidade dos resíduos. Ainda assim, não rejeitou a
normalidade ao nível de 5%.

Com desconfiança da normalidade, usaremos o teste de Levene para verificar
homocedasticidade, com resultados na @tbl-DCA-levene.

```{r}
#| label: tbl-DCA-levene
#| tbl-cap: "Teste de Levene para os resíduos do modelo DCA"
leveneDCA <- leveneTest(residuosDCA ~ Trat, data = dados)
tibleleveneDCA <- tibble(
  Estatística = leveneDCA$`F value`[1],
  "Valor-p" = leveneDCA$`Pr(>F)`[1]
)
kable(tibleleveneDCA, digits = 4)
```

O teste de Levene na @tbl-DCA-levene não rejeita a homocedasticidade dos
resíduos. Ainda assim, o modelo DCA apresenta mais indícios de violação da
normalidade que o modelo DABC, que também modela melhor os dados. Desta forma,
escolheríamos o modelo DABC para descrever esses dados. Por curiosidade,
verificamos também os $R^2$ ajustados dos dois modelos, na @tbl-rsquared.

```{r}
#| label: tbl-rsquared
#| tbl-cap: "R² ajustado dos modelos DCA e DABC"
rsquared <- tibble(
  Modelo = c("DCA", "DABC"),
  "R² Ajustado" = c(
    summary(modeloDCA)$adj.r.squared,
    summary(modeloDABC)$adj.r.squared
  )
)
kable(rsquared, digits = 4)
```

## Item c

Realizaremos o teste de aleatorização para um modelo DABC, considerando que as
assunções de normalidade e homocedasticidade foram satisfeitas.

```{r}
#| output: false
modeloDABCperm <- lmp(Obser ~ Planta + Trat, data = dados)
```

```{r}
#| label: tbl-anova-DABC-perm
#| tbl-cap: "ANOVA por permutação para o modelo DABC"
anovaDABCperm <- anova(modeloDABCperm)
```

De acordo com a @tbl-anova-DABC-perm, o teste de aleatorização também indica
efeito significativo dos tratamentos. O `valor-p` do fator de tratamentos do
teste de aleatorização global é $0$ (menor que $0.0001$).

# Exercício 2

Conferimos os resultados obtidos pela geração de dadaos e implementação da
aleatorização "Manual" no `R`


```{r}
#| label: tbl-rand-manual
#| tbl-cap: "Teste de aleatorização passo-a-passo"
###############################################################
## RANDOMIZATION TEST (Gary Oehlert)
## Estatística F + Comparações múltiplas (a posteriori)
## RCBD com 3 tratamentos — dados fictícios
###############################################################

### ---------------------------------------------------------
### 1. Gerar dados fictícios
### ---------------------------------------------------------

t <- 3 # tratamentos A, B, C
b <- 6 # blocos

trat <- factor(rep(LETTERS[1:t], b))
bloco <- factor(rep(1:b, each = t))

# Médias fictícias
verdades <- c(5, 7, 6.2)

# Dados simulados
y <- rnorm(t * b, mean = rep(verdades, b), sd = 0.6)

dados <- data.frame(bloco, trat, y)

## Função para obter F da ANOVA em blocos
F_stat <- function(y, trat, bloco) {
  # Soma de quadrados tratamentos
  medias_t <- tapply(y, trat, mean)
  media_geral <- mean(y)
  n_i <- table(trat)

  SS_trat <- sum(n_i * (medias_t - media_geral)^2)
  gl_trat <- length(levels(trat)) - 1
  QM_trat <- SS_trat / gl_trat

  # Soma de quadrados bloco
  medias_b <- tapply(y, bloco, mean)
  n_j <- table(bloco)
  SS_bloco <- sum(n_j * (medias_b - media_geral)^2)
  gl_bloco <- length(levels(bloco)) - 1
  QM_bloco <- SS_bloco / gl_bloco

  # Soma de quadrados residual
  SS_total <- sum((y - media_geral)^2)
  SS_res <- SS_total - SS_trat - SS_bloco
  gl_res <- length(y) - (gl_trat + gl_bloco + 1)
  QM_res <- SS_res / gl_res

  F <- QM_bloco / QM_res
  return(F)
}

F_obs <- F_stat(y, trat, bloco)
B <- 5000
F_perm <- numeric(B)

for (k in 1:B) {
  trat_perm <- unlist(tapply(trat, bloco, sample))
  F_perm[k] <- F_stat(y, trat_perm, bloco)
}

p_value_global <- mean(F_perm >= F_obs)

pares <- combn(levels(trat), 2, simplify = FALSE)

# estatística observada para cada comparação: diferença absoluta das médias
diff_obs <- sapply(pares, function(par) {
  abs(mean(y[trat == par[1]]) - mean(y[trat == par[2]]))
})
names(diff_obs) <- sapply(pares, paste, collapse = " vs ")

# randomization null distribution para cada comparação
diff_perm <- matrix(0, nrow = B, ncol = length(pares))

for (k in 1:B) {
  trat_perm <- unlist(tapply(trat, bloco, sample))
  for (j in 1:length(pares)) {
    p <- pares[[j]]
    diff_perm[k, j] <- abs(mean(y[trat_perm == p[1]]) -
      mean(y[trat_perm == p[2]]))
  }
}

# p-values individuais
p_raw <- colMeans(diff_perm >= matrix(diff_obs,
  nrow = B, ncol = length(pares),
  byrow = TRUE
))

# Correção para múltiplos testes (Holm)
p_adj <- p.adjust(p_raw, method = "holm")

# Tabela final
comparacoes <- tibble(
  Comparacao = names(diff_obs),
  Dif_observada = diff_obs,
  p_raw,
  p_ajustado_Holm = p_adj
)
kable(comparacoes, digits = 4)
```

Vamos comparar os resultados obtidos no passo-a-passo, na @tbl-rand-manual, com
os obtidos pelo pacote `lmPerm`:

```{r}
#| label: tbl-rand-lmPerm
#| tbl-cap: "Teste de aleatorização com lmPerm"
modelo_perm <- lmp(y ~ bloco + trat, data = dados)
anova_modelo_perm <- anova(modelo_perm)
kable(anova_modelo_perm, digits = 4)
```

\newpage
# Exercício 3

```{r}
tabela_padronizada <- read_excel("Tabela_Padronizada.xlsx")

tabela_padronizada_nona <- na.omit(tabela_padronizada)

# Dividindo entre genes e miRNAs
tabela_padronizada_nonag <- tabela_padronizada_nona[, c(1:8, 13)]
tabela_padronizada_nonam <- tabela_padronizada_nona[, c(9:13)]
```


## Item a

Vamos comparar os grupos do gene `EIF4` e do miRNA `miR_150` primeiramente por medidas-resumos. Abaixo temos as tabelas com as estatísticas.

```{r}
dados_EIF4 <- as.data.frame(cbind(tabela_padronizada_nonag$EIF4, tabela_padronizada_nonag$Fase))
colnames(dados_EIF4) <- c("EIF4", "Fase")
dados_EIF4$Fase <- factor(dados_EIF4$Fase, levels = c("CB", "DS", "FC"))
dados_EIF4$EIF4 <- as.numeric(dados_EIF4$EIF4)
EIF4_CB <- dados_EIF4[dados_EIF4$Fase == "CB", ]
EIF4_DS <- dados_EIF4[dados_EIF4$Fase == "DS", ]
EIF4_FC <- dados_EIF4[dados_EIF4$Fase == "FC", ]
combinado_EIF4 <- list(EIF4_CB = EIF4_CB$EIF4, EIF4_DS = EIF4_DS$EIF4, EIF4_FC = EIF4_FC$EIF4)

gene <- rep("EIF4", 3)
grupo <- c("CB (n = 14)", "DS (n = 8)", "FC (n = 50)")
minimo <- round(sapply(combinado_EIF4, min), digits = 4)
mediana <- round(sapply(combinado_EIF4, median), digits = 4)
media <- round(sapply(combinado_EIF4, mean), digits = 4)
maximo <- round(sapply(combinado_EIF4, max), digits = 4)
desvio_padrao <- round(sapply(combinado_EIF4, sd), digits = 4)
erro_padrao <- round(sapply(combinado_EIF4, sd) / sqrt(sapply(combinado_EIF4, length)), digits = 4)

tabela_EIF4 <- data.frame(
  Gene = gene,
  Grupo = grupo,
  Min = minimo,
  Med = mediana,
  Mean = media,
  Max = maximo,
  DP = desvio_padrao,
  EP = erro_padrao
)


dados_miR_150 <- as.data.frame(cbind(tabela_padronizada_nonam$miR_150, tabela_padronizada_nonam$Fase))
colnames(dados_miR_150) <- c("miR_150", "Fase")
dados_miR_150$Fase <- factor(dados_miR_150$Fase, levels = c("CB", "DS", "FC"))
dados_miR_150$miR_150 <- as.numeric(dados_miR_150$miR_150)
miR_150_CB <- dados_miR_150[dados_miR_150$Fase == "CB", ]
miR_150_DS <- dados_miR_150[dados_miR_150$Fase == "DS", ]
miR_150_FC <- dados_miR_150[dados_miR_150$Fase == "FC", ]
combinado_miR_150 <- list(miR_150_CB = miR_150_CB$miR_150, miR_150_DS = miR_150_DS$miR_150, miR_150_FC = miR_150_FC$miR_150)

gene <- rep("miR_150", 3)
grupo <- c("CB (n = 14)", "DS (n = 8)", "FC (n = 50)")
minimo <- round(sapply(combinado_miR_150, min), digits = 4)
mediana <- round(sapply(combinado_miR_150, median), digits = 4)
media <- round(sapply(combinado_miR_150, mean), digits = 4)
maximo <- round(sapply(combinado_miR_150, max), digits = 4)
desvio_padrao <- round(sapply(combinado_miR_150, sd), digits = 4)
erro_padrao <- round(sapply(combinado_miR_150, sd) / sqrt(sapply(combinado_miR_150, length)), digits = 4)

tabela_miR_150 <- data.frame(
  Gene = gene,
  Grupo = grupo,
  Min = minimo,
  Med = mediana,
  Mean = media,
  Max = maximo,
  DP = desvio_padrao,
  EP = erro_padrao
)
```

```{r}
#| label: tbl-resumo-eif4
#| tbl-cap: "Medidas-resumo para o gene 'EIF4'"

kable(tabela_EIF4, row.names = FALSE)
```

```{r}
#| label: tbl-resumo-mir150
#| tbl-cap: "Medidas-resumo para o gene 'miR_150'"

kable(tabela_miR_150, row.names = FALSE)
```

Ao analisar a @tbl-resumo-eif4 e a @tbl-resumo-mir150, apesar do alto desvio-padrão, podemos perceber que tanto em `EIF4` e `miR_150`, as medidas quantílicas e a média amostral diferem entre si. Iremos testar a hipótese de que não há diferença entre os grupos usando um teste de permutação, com `maxIter` $= 1000$ para ser igual ao trabalho do CEA.

```{r}
#| label: tbl-anova-perm-eif4
#| tbl-cap: "ANOVA por permutação para 'EIF4'"
model_EIF4 <- lmp(EIF4 ~ Fase,
  data = dados_EIF4,
  maxIter = 1000
)

anova_perm_EIF4 <- anova(model_EIF4)
```

```{r}
#| label: tbl-anova-perm-mir150
#| tbl-cap: "ANOVA por permutação para 'miR_150'"
model_miR_150 <- lmp(miR_150 ~ Fase,
  data = dados_miR_150,
  maxIter = 1000
)
anova_perm_miR_150 <- anova(model_miR_150)
```

Como podemos perceber pelas tabelas, ao nível de significância de $0.05$, há evidências para rejeitarmos ambas as hipóteses nulas iniciais, separadamente. Ou seja, há evidências para rejeitar que não há diferença entre os grupos para `EIF4` e `miR_150`.

<!-- ## Item b -->
<!---->
<!-- ```{r} -->
<!-- # Aplicação do adonis -->
<!-- Y <- tabela_padronizada_nona[, c(1:12)] -->
<!-- adonis_ambos <- adonis2(Y ~ tabela_padronizada_nona$Fase, method = "euclidean") -->
<!-- post_hoc_ambos <- pairwise.adonis(Y, tabela_padronizada_nona$Fase, sim.method = "euclidean", p.adjust.m = "bonferroni") -->
<!---->
<!---->
<!-- Y <- tabela_padronizada_nonag[, c(1:8)] -->
<!-- adonis_genes <- adonis2(Y ~ tabela_padronizada_nonag$Fase, method = "euclidean") -->
<!-- post_hoc_genes <- pairwise.adonis(Y, tabela_padronizada_nonag$Fase, sim.method = "euclidean", p.adjust.m = "bonferroni") -->
<!---->
<!---->
<!-- Y <- tabela_padronizada_nonam[, c(1:4)] -->
<!-- adonis_miRNAs <- adonis2(Y ~ tabela_padronizada_nonam$Fase, method = "euclidean") -->
<!-- post_hoc_miRNAs <- pairwise.adonis(Y, tabela_padronizada_nonam$Fase, sim.method = "euclidean", p.adjust.m = "bonferroni") -->
<!-- ``` -->
<!---->
<!-- ```{r} -->
<!-- # Aplicação do nonpartest -->
<!-- nonpartest_ambos <- nonpartest(TP53 | CDKN1A | PTEN | MDM4 | MYB | SHIP | EIF4 | CEBPB | miR_155 | miR_150 | miR_34a | miR_17_5p ~ Fase, data = tabela_padronizada_nona, permreps = 1000, plots = FALSE) -->
<!---->
<!-- nonpartest_genes <- nonpartest(TP53 | CDKN1A | PTEN | MDM4 | MYB | SHIP | EIF4 | CEBPB ~ Fase, data = tabela_padronizada_nonag, permreps = 1000, plots = FALSE) -->
<!---->
<!-- nonpartest_miRNAs <- nonpartest(miR_155 | miR_150 | miR_34a | miR_17_5p ~ Fase, data = tabela_padronizada_nonam, permreps = 1000, plots = FALSE) -->
<!-- ``` -->
<!---->
<!-- Primeiramente, aplicaremos a PERMANOVA usando o pacote `adonis2` para as 3 situações: -->
<!---->
<!-- - Situação 1: 12 variáveis dependentes (os 8 genes e os 4 miRNAs) e 1 variável -->
<!-- independente (classificação dos grupos DS, FC, e CB). -->
<!-- - Situação 2: 8 variáveis dependentes (os 8 genes) e 1 variável independente (a -->
<!-- classificação dos os grupos: DS, FC, e CB). -->
<!-- - Situação 3: 4 variáveis dependentes (os 4 miRNAs) e 1 variável independente (a -->
<!-- classificação dos grupos: DS, FC, e CB). -->
<!---->
<!-- Adotaremos um nível de significância $\alpha = 0.05$. -->
<!---->
<!-- Abaixo, mostramos as saídas da PERMANOVA para as 3 situações, respectivamente. -->
<!---->
<!-- ```{r} -->
<!-- #| label: tbl-1-PERMANOVA -->
<!-- #| tbl-cap: "PERMANOVA para a situação 1" -->
<!-- kable(adonis_ambos, digits = 4) -->
<!-- ``` -->
<!---->
<!-- ```{r} -->
<!-- #| label: tbl-2-PERMANOVA -->
<!-- #| tbl-cap: "PERMANOVA para a situação 2" -->
<!-- kable(adonis_genes, digits = 4) -->
<!-- ``` -->
<!---->
<!-- ```{r} -->
<!-- #| label: tbl-3-PERMANOVA -->
<!-- #| tbl-cap: "PERMANOVA para a situação 3" -->
<!-- kable(adonis_miRNAs, digits = 4) -->
<!-- ``` -->
<!---->
<!-- No teste, a hipótese nula é de igualdade dos grupos por variável dependente (a depender das 3 situações acima mencionadas), para todas variáveis dependentes.  -->
<!---->
<!-- Para as 3 situações, a um nível de significância $\alpha$, há evidências para rejeitar a hipótese nula, ou seja, caso considerarmos um espaço de hipóteses fechado, há evidências de que existe diferença em pelo menos um grupo dentro de uma variável dependente, pelo menos em uma variável dependente. -->
<!---->
<!-- Aplicaremos testes post hoc para entendermos quais grupos diferem, em especial, o post hoc de Bonferroni. Usaremos a função `pairwise.adonis`. -->
<!---->
<!-- Abaixo, mostramos as saídas do post hoc para as 3 situações, respectivamente. -->
<!---->
<!-- ```{r} -->
<!-- #| label: tbl-1-posthoc -->
<!-- #| tbl-cap: "Post Hoc para a situação 1" -->
<!-- kable(post_hoc_ambos, digits = 4) -->
<!-- ``` -->
<!---->
<!-- ```{r} -->
<!-- #| label: tbl-2-posthoc -->
<!-- #| tbl-cap: "Post Hoc para a situação 2" -->
<!-- kable(post_hoc_genes, digits = 4) -->
<!-- ``` -->
<!---->
<!-- ```{r} -->
<!-- #| label: tbl-3-posthoc -->
<!-- #| tbl-cap: "Post Hoc para a situação 3" -->
<!-- kable(post_hoc_miRNAs, digits = 4) -->
<!-- ``` -->
<!---->
<!-- Para a situação 1 (@tbl-1-posthoc) as comparações entre os pares FC vs CB (valor-p = $0.001$, valor=p ajustado = $0.003$), FC vs DS (valor-p = $0.001$, valor-p ajustado = $0.003$) e CB vs DS (valor-p = $0.005$, valor=p ajustado = $0.015$) foram todas significativas estaticamente, portanto havendo evidências de que os grupos apresentam diferenças entre si. -->
<!---->
<!-- Para a situação 2 (@tbl-2-posthoc) as comparações entre os pares FC vs CB (valor-p = $0.001$, valor=p ajustado = $0.003$) e FC vs DS (valor-p = $0.004$, valor-p ajustado = $0.012$) foram significativas estaticamente, portanto havendo evidências de que o grupo FC difere de CB e que o grupo FC difere de DS. A comparação CB vs DS (valor-p = $0.055$, valor=p ajustado = $0.165$) não foi estatisticamente significante, não havendo evidências para rejeitar que os grupos CB e DS possuam igualdades. -->
<!---->
<!-- Para a situação 3 (@tbl-3-posthoc) as comparações entre os pares FC vs CB (valor-p = $0.001$, valor-p ajustado = $0.003$), FC vs DS (valor-p = $0.001$, valor=p ajustado = $0.003$) e CB vs DS (valor-p = $0.007$, valor=p ajustado = $0.021$) foram todas significativas estaticamente, portanto havendo evidências de que os grupos apresentam diferenças entre si. -->
<!---->
<!---->
<!-- Adicionalmente, iremos aplicar os testes `nonpartest` sobre os dados. É uma coleção de testes não-paramétricos multivariados, que, especialmente, tem uma interpretação bem mais fácil do que o `adonis`: adquire-se o efeito de tratamento "k" caso o que pode ser definido como a probabilidade de que um sujeito escolhido aleatoriamente do tratamento “k”, que neste estudo não é outra coisa que o grupo, exiba um nível de expressão mais alto do que um sujeito escolhido aleatoriamente de qualquer um dos grupos de tratamento, -->
<!-- incluindo o tratamento “k”. Essa probabilidade é mostrada nas tabelas 'releffects' a seguir. -->
<!---->
<!-- Abaixo, mostramos as saídas do `nonpartest` para as 3 situações, respectivamente, com 2 tabelas por situação. -->
<!---->
<!-- ```{r} -->
<!-- #| label: tbl-1.1-nonpartest -->
<!-- #| tbl-cap: "Tabela 'results': nonpartest para a situação 1" -->
<!-- kable(nonpartest_ambos$results, digits = 4) -->
<!-- ``` -->
<!---->
<!-- ```{r} -->
<!-- #| label: tbl-1.2-nonpartest -->
<!-- #| tbl-cap: "Tabela 'releffects': nonpartest para a situação 1" -->
<!-- colnames(nonpartest_ambos$releffects) <- gsub("miR|_", "", colnames(nonpartest_ambos$releffects)) -->
<!-- colnames(nonpartest_ambos$releffects)[2] <- "CDK" -->
<!-- kable(nonpartest_ambos$releffects, digits = 4) -->
<!-- ``` -->
<!---->
<!-- Obs: a @tbl-1.2-nonpartest tem alguns nomes de coluna alterados para a visualização. A 2ª coluna corresponde ao gene CDKN1A e as últimas 4 colunas correspondem aos miRNAs, respectivamente: miR_155, miR_150, miR_34a, miR_17_5p -->
<!---->
<!-- ```{r} -->
<!-- #| label: tbl-2.1-nonpartest -->
<!-- #| tbl-cap: "Tabela 'results': nonpartest para a situação 2" -->
<!-- kable(nonpartest_genes$results, digits = 4) -->
<!-- ``` -->
<!---->
<!-- ```{r} -->
<!-- #| label: tbl-2.2-nonpartest -->
<!-- #| tbl-cap: "Tabela 'releffects': nonpartest para a situação 2" -->
<!-- kable(nonpartest_genes$releffects, digits = 4) -->
<!-- ``` -->
<!---->
<!-- ```{r} -->
<!-- #| label: tbl-3.1-nonpartest -->
<!-- #| tbl-cap: "Tabela 'results': nonpartest para a situação 3" -->
<!-- kable(nonpartest_miRNAs$results, digits = 4) -->
<!-- ``` -->
<!---->
<!-- ```{r} -->
<!-- #| label: tbl-3.2-nonpartest -->
<!-- #| tbl-cap: "Tabela 'releffects': nonpartest para a situação 3" -->
<!-- kable(nonpartest_miRNAs$releffects, digits = 4) -->
<!-- ``` -->
<!---->
<!-- Ao olhar a @tbl-1.1-nonpartest, a @tbl-2.1-nonpartest e a @tbl-3.1-nonpartest, podemos perceber que em todas as situações o valor-p e o valor-p de permutação foram iguais a $0$ entre os grupos, para todos os testes multivariados de igualdade de grupos. Ou seja, nas 1000 permutações, nenhuma contribuiu para $H_0$. -->
<!---->
<!-- Se desejarmos, podemos também analisar a @tbl-1.2-nonpartest, a @tbl-2.2-nonpartest e a @tbl-3.2-nonpartest para avaliar os efeitos relativos entre cada variável dependente e seus grupos. Acreditamos que os testes anteriores já são suficientes. -->
<!---->
<!-- **Conclusão:** Foi possível verificar que as expressões dos genes e dos miRNAs apresentaram diferenças significativas entre os grupos estudados. -->
